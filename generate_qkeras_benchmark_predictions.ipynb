{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:34:57.016789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-30 17:34:57.297278: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-30 17:34:57.313248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:34:57.313328: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-06-30 17:34:58.003877: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:34:58.004029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:34:58.004037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from recurrent.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aelabd/RHEED/hls4ml/hls4ml/converters/__init__.py:29: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import parse_default_keras_layer\n",
    "from hls4ml.model.attributes import ConfigurableAttribute, TypeAttribute\n",
    "from hls4ml.model.types import FixedPrecisionType, RoundingMode, SaturationMode\n",
    "from hls4ml.model.attributes import Attribute\n",
    "\n",
    "import h5py\n",
    "\n",
    "import qkeras as qk\n",
    "from qkeras.estimate import print_qstats\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.utils import quantized_model_dump\n",
    "from qkeras import QActivation, QDense, QConv2DBatchnorm\n",
    "\n",
    "# Source the Vivado path\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quantization_info(model):\n",
    "    for layer in model.layers:\n",
    "        print(f\"Layer Name: {layer.name}\")\n",
    "        print(f\"Type: {layer.__class__.__name__}\")\n",
    "        \n",
    "        # Helper function to handle both quantizer objects and config dicts\n",
    "        def process_quantizer(quantizer, prefix=\"\"):\n",
    "            if quantizer:\n",
    "                if isinstance(quantizer, dict):\n",
    "                    # Handle dictionary config\n",
    "                    class_name = quantizer.get(\"class_name\", \"UnknownQuantizer\")\n",
    "                    config = quantizer.get(\"config\", {})\n",
    "                else:\n",
    "                    # Handle object with potential get_config()\n",
    "                    class_name = quantizer.__class__.__name__\n",
    "                    config = quantizer.get_config() if hasattr(quantizer, \"get_config\") else {}\n",
    "                \n",
    "                print(f\"  {prefix}Quantizer: {class_name}\")\n",
    "                print(f\"  {prefix}Config: {config}\")\n",
    "            else:\n",
    "                print(f\"  No {prefix}Quantizer\")\n",
    "\n",
    "        # Check for QKeras layers with kernel/bias quantizers\n",
    "        if isinstance(layer, (qk.QDense, qk.QConv2D, qk.QConv1D, \n",
    "                            qk.QConv2DTranspose, qk.QDepthwiseConv2D)):\n",
    "            # Kernel quantizer\n",
    "            process_quantizer(layer.kernel_quantizer, \"Kernel \")\n",
    "            \n",
    "            # Bias quantizer\n",
    "            process_quantizer(layer.bias_quantizer, \"Bias \")\n",
    "            \n",
    "            # Activation quantizer\n",
    "            activation = layer.activation\n",
    "            if activation:\n",
    "                if isinstance(activation, dict) or hasattr(activation, \"get_config\"):\n",
    "                    process_quantizer(activation, \"Activation \")\n",
    "                else:\n",
    "                    print(f\"  Activation: {activation} (Not Quantized)\")\n",
    "            else:\n",
    "                print(\"  No Activation\")\n",
    "\n",
    "        # Check for QActivation layers\n",
    "        elif isinstance(layer, qk.QActivation):\n",
    "            process_quantizer(layer.quantizer, \"Activation \")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def generate_binary_numbers(n_bits):\n",
    "    return np.array([''.join(bits) for bits in itertools.product('01', repeat=n_bits)])\n",
    "\n",
    "def bin_to_int(bin_str):\n",
    "    int_val = 0\n",
    "    for i, bit in enumerate(bin_str[::-1]):\n",
    "        int_val += int(bit)*(2**i)\n",
    "    return int_val\n",
    "\n",
    "def bin_to_frac(bin_str):\n",
    "    frac_val = 0\n",
    "    for i, bit in enumerate(bin_str):\n",
    "        frac_val += int(bit)*(2**(-i-1))\n",
    "    return frac_val\n",
    "\n",
    "def frac_to_bin(frac, n_bits=8):\n",
    "    bin_str = \"\"\n",
    "    for i in range(n_bits):\n",
    "        if frac >= 2**(-i-1):\n",
    "            bin_str += \"1\"\n",
    "            frac -= 2**(-i-1)\n",
    "        else:\n",
    "            bin_str += \"0\"\n",
    "    return bin_str\n",
    "\n",
    "def hex_str_to_float_frac(hex_str):\n",
    "    int_num = int(hex_str.replace(\"\\n\", \"\").strip(), 16)\n",
    "    int_bin_str = np.binary_repr(int_num)\n",
    "    float_frac = bin_to_frac(int_bin_str)\n",
    "    return float_frac\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:35:06.235764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-06-30 17:35:06.235978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236160: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236228: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2025-06-30 17:35:06.236302: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-06-30 17:35:06.237718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aelabd/miniconda3/envs/rheed_hls4ml_dev/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aelabd/miniconda3/envs/rheed_hls4ml_dev/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: q_conv2d_batchnorm_5\n",
      "Type: QConv2DBatchnorm\n",
      "  Kernel Quantizer: quantized_bits\n",
      "  Kernel Config: {'bits': 8, 'integer': 0, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Bias Quantizer: quantized_bits\n",
      "  Bias Config: {'bits': 8, 'integer': 0, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Activation: <function linear at 0x7feef6eb4430> (Not Quantized)\n",
      "--------------------------------------------------\n",
      "Layer Name: q_activation_8\n",
      "Type: QActivation\n",
      "  Activation Quantizer: quantized_relu\n",
      "  Activation Config: {'bits': 8, 'integer': 2, 'use_sigmoid': 0, 'negative_slope': 0.0, 'use_stochastic_rounding': False, 'relu_upper_bound': None, 'qnoise_factor': 1.0}\n",
      "--------------------------------------------------\n",
      "Layer Name: max_pooling2d_5\n",
      "Type: MaxPooling2D\n",
      "--------------------------------------------------\n",
      "Layer Name: q_conv2d_batchnorm_6\n",
      "Type: QConv2DBatchnorm\n",
      "  Kernel Quantizer: quantized_bits\n",
      "  Kernel Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Bias Quantizer: quantized_bits\n",
      "  Bias Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Activation: <function linear at 0x7feef6eb4430> (Not Quantized)\n",
      "--------------------------------------------------\n",
      "Layer Name: q_activation_9\n",
      "Type: QActivation\n",
      "  Activation Quantizer: quantized_relu\n",
      "  Activation Config: {'bits': 8, 'integer': 2, 'use_sigmoid': 0, 'negative_slope': 0.0, 'use_stochastic_rounding': False, 'relu_upper_bound': None, 'qnoise_factor': 1.0}\n",
      "--------------------------------------------------\n",
      "Layer Name: max_pooling2d_6\n",
      "Type: MaxPooling2D\n",
      "--------------------------------------------------\n",
      "Layer Name: q_conv2d_batchnorm_7\n",
      "Type: QConv2DBatchnorm\n",
      "  Kernel Quantizer: quantized_bits\n",
      "  Kernel Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Bias Quantizer: quantized_bits\n",
      "  Bias Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Activation: <function linear at 0x7feef6eb4430> (Not Quantized)\n",
      "--------------------------------------------------\n",
      "Layer Name: q_activation_10\n",
      "Type: QActivation\n",
      "  Activation Quantizer: quantized_relu\n",
      "  Activation Config: {'bits': 8, 'integer': 2, 'use_sigmoid': 0, 'negative_slope': 0.0, 'use_stochastic_rounding': False, 'relu_upper_bound': None, 'qnoise_factor': 1.0}\n",
      "--------------------------------------------------\n",
      "Layer Name: max_pooling2d_7\n",
      "Type: MaxPooling2D\n",
      "--------------------------------------------------\n",
      "Layer Name: global_average_pooling2d_1\n",
      "Type: GlobalAveragePooling2D\n",
      "--------------------------------------------------\n",
      "Layer Name: q_dense_5\n",
      "Type: QDense\n",
      "  Kernel Quantizer: quantized_bits\n",
      "  Kernel Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Bias Quantizer: quantized_bits\n",
      "  Bias Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Activation: <function linear at 0x7feef6eb4430> (Not Quantized)\n",
      "--------------------------------------------------\n",
      "Layer Name: q_activation_11\n",
      "Type: QActivation\n",
      "  Activation Quantizer: quantized_relu\n",
      "  Activation Config: {'bits': 8, 'integer': 2, 'use_sigmoid': 0, 'negative_slope': 0.0, 'use_stochastic_rounding': False, 'relu_upper_bound': None, 'qnoise_factor': 1.0}\n",
      "--------------------------------------------------\n",
      "Layer Name: q_dense_6\n",
      "Type: QDense\n",
      "  Kernel Quantizer: quantized_bits\n",
      "  Kernel Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Bias Quantizer: quantized_bits\n",
      "  Bias Config: {'bits': 8, 'integer': 2, 'symmetric': 0, 'alpha': 1, 'keep_negative': True, 'use_stochastic_rounding': False, 'qnoise_factor': 1.0}\n",
      "  Activation: <function linear at 0x7feef6eb4430> (Not Quantized)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "KERAS_DIR = \"/home/aelabd/RHEED/keras_models\"\n",
    "RTL_DIR = \"/home/aelabd/RHEED/rtl_models\"\n",
    "\n",
    "def dice_loss(y_true, y_pred, delta=0.6):\n",
    "    error = y_true - y_pred\n",
    "    is_small = tf.abs(error) <= delta\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
    "    return tf.reduce_mean(tf.where(is_small, squared_loss, linear_loss))\n",
    "\n",
    "fpath_model_keras = os.path.join(KERAS_DIR, \"model.keras\")\n",
    "with tf.keras.utils.custom_object_scope({'dice_loss': dice_loss,\n",
    "                                         'QConv2DBatchnorm': QConv2DBatchnorm,\n",
    "                                         'QActivation': QActivation,\n",
    "                                         'QDense': QDense\n",
    "                                         }):\n",
    "        model = tf.keras.models.load_model(fpath_model_keras)\n",
    "\n",
    "print_quantization_info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load testbench input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_ROWS = 100\n",
    "IN_COLS = 160\n",
    "OUT_ROWS = 48\n",
    "OUT_COLS = 48\n",
    "NUM_CROPS = 1\n",
    "data_dir = f\"tb_data_Mono8/{IN_ROWS}x{IN_COLS}_to_{OUT_ROWS}x{OUT_COLS}x{NUM_CROPS}\"\n",
    "\n",
    "CROP_X0 = [0, 13, 112]\n",
    "CROP_Y0 = [0, 1, 52]\n",
    "input_data = {}\n",
    "for y0 in CROP_Y0:\n",
    "    input_data[f\"y1_{y0}\"] = {}\n",
    "    for x0 in CROP_X0:\n",
    "        crop_data = []\n",
    "        fpath = os.path.join(data_dir, f\"Y1_{y0}/X1_{x0}/HDL_cropnorm_out.txt\")\n",
    "        with open(fpath, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "\n",
    "                line_float = np.zeros((OUT_COLS,))\n",
    "                for i, hex_str in enumerate(line.split(\" \")):\n",
    "                    hex_str_clean = hex_str.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "                    if len(hex_str_clean) < 1: continue\n",
    "                    line_float[i] = hex_str_to_float_frac(hex_str_clean)\n",
    "\n",
    "                crop_data.append(line_float)\n",
    "        input_data[f\"y1_{y0}\"][f\"x1_{x0}\"] = np.expand_dims(np.expand_dims(np.array(crop_data), 0), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Output quantization is <8,2> not <8,0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000001101000000000\n",
      "1111111110110000000000\n"
     ]
    }
   ],
   "source": [
    "def float_to_ap_fixed(value, X, Y):\n",
    "    \"\"\"\n",
    "    Converts a float to a binary string representing a signed ap_fixed<X,Y> number.\n",
    "    \n",
    "    Parameters:\n",
    "        value (float): The float value to convert.\n",
    "        X (int): Total number of bits.\n",
    "        Y (int): Number of integer bits (including sign bit).\n",
    "    \n",
    "    Returns:\n",
    "        str: Binary string of length X.\n",
    "    \"\"\"\n",
    "    # Number of fractional bits\n",
    "    F = X - Y\n",
    "\n",
    "    # Compute scaled integer\n",
    "    scaled = int(round(value * (2 ** F)))\n",
    "\n",
    "    # Calculate min and max representable values\n",
    "    min_val = -(2 ** (X - 1))\n",
    "    max_val = (2 ** (X - 1)) - 1\n",
    "\n",
    "    # Clip to representable range\n",
    "    if scaled < min_val:\n",
    "        scaled = min_val\n",
    "    elif scaled > max_val:\n",
    "        scaled = max_val\n",
    "\n",
    "    # Convert to two's complement binary\n",
    "    if scaled < 0:\n",
    "        scaled = (1 << X) + scaled  # two's complement\n",
    "\n",
    "    bin_str = format(scaled, f'0{X}b')  # zero-padded binary string of width X\n",
    "    return bin_str\n",
    "\n",
    "print(float_to_ap_fixed(3.25, 22, 11))   # ap_fixed<8,4> => 4 int bits, 4 fractional bits\n",
    "# Output: '00110100'  (3.25 * 16 = 52 => 0b00110100)\n",
    "\n",
    "print(float_to_ap_fixed(-2.5, 22, 11))\n",
    "# Output: '11000000'  (-2.5 * 16 = -40 => two's complement => 0b11000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0=0, x0=0\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "val: 0.451171875, bin_str: 0000000000001110011100\n",
      "val: 0.5185546875, bin_str: 0000000000010000100110\n",
      "val: -0.63134765625, bin_str: 1111111111101011110011\n",
      "val: -0.43115234375, bin_str: 1111111111110010001101\n",
      "val: -0.12060546875, bin_str: 1111111111111100001001\n",
      "y0=0, x0=13\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val: 0.45068359375, bin_str: 0000000000001110011011\n",
      "val: 0.51904296875, bin_str: 0000000000010000100111\n",
      "val: -0.63720703125, bin_str: 1111111111101011100111\n",
      "val: -0.43017578125, bin_str: 1111111111110010001111\n",
      "val: -0.11669921875, bin_str: 1111111111111100010001\n",
      "y0=0, x0=112\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val: 0.451171875, bin_str: 0000000000001110011100\n",
      "val: 0.5185546875, bin_str: 0000000000010000100110\n",
      "val: -0.63134765625, bin_str: 1111111111101011110011\n",
      "val: -0.43115234375, bin_str: 1111111111110010001101\n",
      "val: -0.12060546875, bin_str: 1111111111111100001001\n",
      "y0=1, x0=0\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val: 0.45556640625, bin_str: 0000000000001110100101\n",
      "val: 0.52734375, bin_str: 0000000000010000111000\n",
      "val: -0.66015625, bin_str: 1111111111101010111000\n",
      "val: -0.45556640625, bin_str: 1111111111110001011011\n",
      "val: -0.11865234375, bin_str: 1111111111111100001101\n",
      "y0=1, x0=13\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val: 0.45654296875, bin_str: 0000000000001110100111\n",
      "val: 0.52392578125, bin_str: 0000000000010000110001\n",
      "val: -0.66552734375, bin_str: 1111111111101010101101\n",
      "val: -0.45361328125, bin_str: 1111111111110001011111\n",
      "val: -0.11083984375, bin_str: 1111111111111100011101\n",
      "y0=1, x0=112\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val: 0.45556640625, bin_str: 0000000000001110100101\n",
      "val: 0.52734375, bin_str: 0000000000010000111000\n",
      "val: -0.66015625, bin_str: 1111111111101010111000\n",
      "val: -0.45556640625, bin_str: 1111111111110001011011\n",
      "val: -0.11865234375, bin_str: 1111111111111100001101\n",
      "y0=52, x0=0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "val: 0.4453125, bin_str: 0000000000001110010000\n",
      "val: 0.5185546875, bin_str: 0000000000010000100110\n",
      "val: -0.595703125, bin_str: 1111111111101100111100\n",
      "val: -0.41064453125, bin_str: 1111111111110010110111\n",
      "val: -0.1484375, bin_str: 1111111111111011010000\n",
      "y0=52, x0=13\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "val: 0.4443359375, bin_str: 0000000000001110001110\n",
      "val: 0.51806640625, bin_str: 0000000000010000100101\n",
      "val: -0.595703125, bin_str: 1111111111101100111100\n",
      "val: -0.4111328125, bin_str: 1111111111110010110110\n",
      "val: -0.1484375, bin_str: 1111111111111011010000\n",
      "y0=52, x0=112\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "val: 0.4453125, bin_str: 0000000000001110010000\n",
      "val: 0.5185546875, bin_str: 0000000000010000100110\n",
      "val: -0.595703125, bin_str: 1111111111101100111100\n",
      "val: -0.41064453125, bin_str: 1111111111110010110111\n",
      "val: -0.1484375, bin_str: 1111111111111011010000\n"
     ]
    }
   ],
   "source": [
    "pred_data = {}\n",
    "output_data = {}\n",
    "for y0 in CROP_Y0:\n",
    "    pred_data[f\"y1_{y0}\"] = {}\n",
    "    for x0 in CROP_X0:\n",
    "        print(f\"y0={y0}, x0={x0}\")\n",
    "        pred = model.predict(input_data[f\"y1_{y0}\"][f\"x1_{x0}\"])[0]\n",
    "        pred_data[f\"y1_{y0}\"][f\"x1_{x0}\"] = pred\n",
    "        fpath_txt = os.path.join(data_dir, f\"Y1_{y0}/X1_{x0}/QKeras_pred_ap_fixed_22_11.txt\")\n",
    "        with open(fpath_txt, \"w\") as f:\n",
    "            for val in pred:\n",
    "                bin_str = float_to_ap_fixed(val, 22, 11)\n",
    "                int_num = bin_to_int(bin_str)\n",
    "                hex_str = hex(int_num).replace(\"0x\", \"\").upper()\n",
    "                if len(hex_str) < 2: hex_str = \"0\" + hex_str\n",
    "                f.write(f\"{hex_str} \")\n",
    "                print(f\"val: {val}, bin_str: {bin_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheed_hls4ml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
