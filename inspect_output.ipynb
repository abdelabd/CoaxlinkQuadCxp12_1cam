{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 17:50:08.987221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-04 17:50:09.071010: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-04 17:50:09.074315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-07-04 17:50:09.074337: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-07-04 17:50:09.540031: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-07-04 17:50:09.540151: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-07-04 17:50:09.540158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from recurrent.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aelabd/RHEED/hls4ml/hls4ml/converters/__init__.py:29: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import parse_default_keras_layer\n",
    "from hls4ml.model.attributes import ConfigurableAttribute, TypeAttribute\n",
    "from hls4ml.model.types import FixedPrecisionType, RoundingMode, SaturationMode\n",
    "from hls4ml.model.attributes import Attribute\n",
    "\n",
    "import h5py\n",
    "\n",
    "import qkeras as qk\n",
    "from qkeras.estimate import print_qstats\n",
    "from qkeras.utils import model_quantize\n",
    "from qkeras.utils import quantized_model_dump\n",
    "from qkeras import QActivation, QDense, QConv2DBatchnorm\n",
    "\n",
    "# Source the Vivado path\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25\n",
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "def ap_fixed_bin_to_float(bin_str: str, X: int, Y: int) -> np.float32:\n",
    "    \"\"\"\n",
    "    Converts a binary string in two's complement ap_fixed<X,Y> format to a float.\n",
    "    \n",
    "    Parameters:\n",
    "        bin_str (str): Binary string of length X.\n",
    "        X (int): Total number of bits.\n",
    "        Y (int): Number of integer bits (including sign bit).\n",
    "        \n",
    "    Returns:\n",
    "        np.float32: Floating point value.\n",
    "    \"\"\"\n",
    "    if len(bin_str) != X:\n",
    "        raise ValueError(f\"Binary string length ({len(bin_str)}) must match X ({X})\")\n",
    "    \n",
    "    # Interpret binary string as signed integer\n",
    "    int_val = int(bin_str, 2)\n",
    "    if bin_str[0] == '1':  # Negative number (two's complement)\n",
    "        int_val -= (1 << X)\n",
    "    \n",
    "    # Scale back by number of fractional bits\n",
    "    frac_bits = X - Y\n",
    "    value = int_val / (2 ** frac_bits)\n",
    "    return np.float32(value)\n",
    "\n",
    "print(ap_fixed_bin_to_float('00110100', 8, 4))  # 3.25\n",
    "print(ap_fixed_bin_to_float('11100000', 8, 4))  # -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load QKeras output (benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39941406 0.58105469 0.72265625 0.50097656 0.02880859]\n",
      " [0.39355469 0.60644531 0.734375   0.49902344 0.02685547]\n",
      " [0.31835938 0.61376953 0.84277344 0.58789062 0.16748047]\n",
      " [0.52929688 0.44433594 0.79394531 0.57666016 0.07861328]\n",
      " [0.42431641 0.38525391 0.82470703 0.62451172 0.3203125 ]]\n"
     ]
    }
   ],
   "source": [
    "IN_ROWS = 300\n",
    "IN_COLS = 320\n",
    "OUT_ROWS = 48\n",
    "OUT_COLS = 48\n",
    "NUM_CROPS = 5\n",
    "data_dir = f\"tb_data_Mono8/{IN_ROWS}x{IN_COLS}_to_{OUT_ROWS}x{OUT_COLS}x{NUM_CROPS}\"\n",
    "\n",
    "TOTAL_BITS = 22\n",
    "INT_BITS = 11\n",
    "\n",
    "CROP_Y0_X0 = [(0,0), (0,30), (20,0), (40,40), (252, 272)]\n",
    "qkeras_out = np.zeros((5, 5))\n",
    "i = 0\n",
    "\n",
    "for (y0,x0) in CROP_Y0_X0:\n",
    "    if y0==0 and x0==13: continue\n",
    "    fpath = os.path.join(data_dir, f\"Y1_{y0}_X1_{x0}/QKeras_mg1_pred_ap_fixed_22_11.txt\")\n",
    "    with open(fpath, \"r\") as f:\n",
    "        for j, line in enumerate(f.readlines()):\n",
    "            line_float = ap_fixed_bin_to_float(line.strip(), TOTAL_BITS, INT_BITS)\n",
    "            qkeras_out[i, j] = line_float\n",
    "        i += 1\n",
    "\n",
    "print(qkeras_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RTL full pipeline output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39941406 0.58105469 0.72265625 0.50097656 0.02880859]\n",
      " [0.39355469 0.60644531 0.734375   0.49902344 0.02685547]\n",
      " [0.31835938 0.61376953 0.84277344 0.58789062 0.16748047]\n",
      " [0.52929688 0.44433594 0.79394531 0.57666016 0.07861328]\n",
      " [0.42431641 0.38525391 0.82470703 0.62451172 0.3203125 ]]\n"
     ]
    }
   ],
   "source": [
    "full_rtl_out = np.zeros((5,5))\n",
    "i=0\n",
    "\n",
    "for (y0,x0) in CROP_Y0_X0:\n",
    "    if y0==0 and x0==13: continue\n",
    "    fpath = os.path.join(data_dir, f\"Y1_{y0}_X1_{x0}/full_RTL_out.txt\")\n",
    "    with open(fpath, \"r\") as f:\n",
    "        for j, line in enumerate(f.readlines()):\n",
    "            line_float = ap_fixed_bin_to_float(line.strip(), TOTAL_BITS, INT_BITS)\n",
    "            full_rtl_out[i, j] = line_float\n",
    "    i += 1\n",
    "\n",
    "print(full_rtl_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare and contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# QKeras CNN - RTL full pipeline\n",
    "print(qkeras_out - full_rtl_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheed_hls4ml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
